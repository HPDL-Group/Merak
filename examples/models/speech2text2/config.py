def load_config(model_name):
    if model_name == "s2t-wav2vec2-large-en-de":
        config = {
            "architectures": [
                "SpeechEncoderDecoderModel"
            ],
            "bos_token_id": 0,
            "decoder": {
                "_name_or_path": "",
                "activation_dropout": 0.1,
                "activation_function": "relu",
                "add_cross_attention": True,
                "architectures": [
                "Speech2TextForConditionalGeneration"
                ],
                "attention_dropout": 0.1,
                "bad_words_ids": None,
                "bos_token_id": 0,
                "chunk_size_feed_forward": 0,
                "classifier_dropout": 0.0,
                "conv_channels": 1024,
                "conv_kernel_sizes": [
                5,
                5
                ],
                "d_model": 256,
                "decoder_attention_heads": 4,
                "decoder_ffn_dim": 2048,
                "decoder_layerdrop": 0.0,
                "decoder_layers": 7,
                "decoder_start_token_id": 2,
                "diversity_penalty": 0.0,
                "do_sample": False,
                "dropout": 0.1,
                "early_stopping": True,
                "encoder_attention_heads": 4,
                "encoder_ffn_dim": 2048,
                "encoder_layerdrop": 0.0,
                "encoder_layers": 12,
                "encoder_no_repeat_ngram_size": 0,
                "eos_token_id": 2,
                "finetuning_task": None,
                "forced_bos_token_id": None,
                "forced_eos_token_id": None,
                "gradient_checkpointing": False,
                "id2label": {
                "0": "LABEL_0",
                "1": "LABEL_1"
                },
                "init_std": 0.02,
                "input_channels": 1,
                "input_feat_per_channel": 80,
                "is_decoder": True,
                "is_encoder_decoder": True,
                "label2id": {
                "LABEL_0": 0,
                "LABEL_1": 1
                },
                "length_penalty": 1.0,
                "max_length": 200,
                "max_source_positions": 6000,
                "max_target_positions": 1024,
                "min_length": 0,
                "model_type": "speech_to_text_2",
                "no_repeat_ngram_size": 0,
                "num_beam_groups": 1,
                "num_beams": 5,
                "num_conv_layers": 2,
                "num_hidden_layers": 7,
                "num_return_sequences": 1,
                "output_attentions": False,
                "output_hidden_states": False,
                "output_scores": False,
                "pad_token_id": 1,
                "prefix": None,
                "problem_type": None,
                "pruned_heads": {},
                "remove_invalid_values": False,
                "repetition_penalty": 1.0,
                "return_dict": True,
                "return_dict_in_generate": False,
                "scale_embedding": True,
                "sep_token_id": None,
                "task_specific_params": None,
                "temperature": 1.0,
                "tie_encoder_decoder": False,
                "tie_word_embeddings": False,
                "tokenizer_class": None,
                "top_k": 50,
                "top_p": 1.0,
                "torch_dtype": None,
                "torchscript": False,
                "transformers_version": "4.10.0.dev0",
                "use_bfloat16": False,
                "use_cache": False,
                'return_dict': False,
                "vocab_size": 10224
            },
            "encoder": {
                "_name_or_path": "",
                "activation_dropout": 0.1,
                "add_cross_attention": False,
                "apply_spec_augment": True,
                "architectures": [
                "Wav2Vec2ForPreTraining"
                ],
                "attention_dropout": 0.1,
                "bad_words_ids": None,
                "bos_token_id": 1,
                "chunk_size_feed_forward": 0,
                "codevector_dim": 768,
                "contrastive_logits_temperature": 0.1,
                "conv_bias": True,
                "conv_dim": [
                512,
                512,
                512,
                512,
                512,
                512,
                512
                ],
                "conv_kernel": [
                10,
                3,
                3,
                3,
                3,
                2,
                2
                ],
                "conv_stride": [
                5,
                2,
                2,
                2,
                2,
                2,
                2
                ],
                "ctc_loss_reduction": "sum",
                "ctc_zero_infinity": False,
                "decoder_start_token_id": None,
                "diversity_loss_weight": 0.1,
                "diversity_penalty": 0.0,
                "do_sample": False,
                "do_stable_layer_norm": True,
                "early_stopping": False,
                "encoder_no_repeat_ngram_size": 0,
                "eos_token_id": 2,
                "feat_extract_activation": "gelu",
                "feat_extract_dropout": 0.0,
                "feat_extract_norm": "layer",
                "feat_proj_dropout": 0.1,
                "feat_quantizer_dropout": 0.0,
                "final_dropout": 0.1,
                "finetuning_task": None,
                "forced_bos_token_id": None,
                "forced_eos_token_id": None,
                "gradient_checkpointing": False,
                "hidden_act": "gelu",
                "hidden_dropout": 0.1,
                "hidden_dropout_prob": 0.1,
                "hidden_size": 1024,
                "id2label": {
                "0": "LABEL_0",
                "1": "LABEL_1"
                },
                "initializer_range": 0.02,
                "intermediate_size": 4096,
                "is_decoder": False,
                "is_encoder_decoder": False,
                "label2id": {
                "LABEL_0": 0,
                "LABEL_1": 1
                },
                "layer_norm_eps": 1e-05,
                "layerdrop": 0.1,
                "length_penalty": 1.0,
                "mask_feature_length": 10,
                "mask_feature_prob": 0.0,
                "mask_time_length": 10,
                "mask_time_prob": 0.05,
                "max_length": 20,
                "min_length": 0,
                "model_type": "wav2vec2",
                "no_repeat_ngram_size": 0,
                "num_attention_heads": 16,
                "num_beam_groups": 1,
                "num_beams": 1,
                "num_codevector_groups": 2,
                "num_codevectors_per_group": 320,
                "num_conv_pos_embedding_groups": 16,
                "num_conv_pos_embeddings": 128,
                "num_feat_extract_layers": 7,
                "num_hidden_layers": 24,
                "num_negatives": 100,
                "num_return_sequences": 1,
                "output_attentions": False,
                "output_hidden_states": False,
                "output_scores": False,
                "pad_token_id": 0,
                "prefix": None,
                "problem_type": None,
                "proj_codevector_dim": 768,
                "pruned_heads": {},
                "remove_invalid_values": False,
                "repetition_penalty": 1.0,
                "return_dict": True,
                "return_dict_in_generate": False,
                "sep_token_id": None,
                "task_specific_params": None,
                "temperature": 1.0,
                "tie_encoder_decoder": False,
                "tie_word_embeddings": True,
                "tokenizer_class": None,
                "top_k": 50,
                "top_p": 1.0,
                "torch_dtype": None,
                "torchscript": False,
                "transformers_version": "4.10.0.dev0",
                "use_bfloat16": False,
                "vocab_size": 32
            },
            "eos_token_id": 2,
            "feature_extractor_type": "wav2vec2",
            "is_encoder_decoder": True,
            "model_type": "speech-encoder-decoder",
            "pad_token_id": 1,
            "tie_word_embeddings": False,
            "tokenizer_class": "speech_to_text_2",
            "torch_dtype": "float32",
            "transformers_version": None,
            "num_beams": 5,
            "max_length": 200
            }
    else:
        raise ValueError(f"No {model_name} config")
    return config